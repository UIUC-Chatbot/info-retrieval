{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from codecs import EncodedFile\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_scheduler,\n",
    ")\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "import json\n",
    "import gzip\n",
    "import random\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  dev = \"cuda:2\"\n",
    "else:\n",
    "  dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = open(\"textbook_embeddings/fine_tune_cleaned_training_data.json\")\n",
    "data = json.load(s)\n",
    "df = pd.DataFrame.from_dict(data, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSMARCOData(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        triplets_path: str,\n",
    "        langs,\n",
    "        max_seq_length: int = 250,\n",
    "        train_batch_size: int = 32,\n",
    "        eval_batch_size: int = 32,\n",
    "        num_negs: int = 3,\n",
    "        cross_lingual_chance: float = 0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.triplets_path = triplets_path\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.langs = langs\n",
    "        self.num_negs = num_negs\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.cross_lingual_chance = cross_lingual_chance  #Probability for cross-lingual batches\n",
    "\n",
    "        #def setup(self, stage: str):\n",
    "        print(f\"!!!!!!!!!!!!!!!!!! SETUP {os.getpid()}  !!!!!!!!!!!!!!!\")\n",
    "\n",
    "        #Get the queries\n",
    "        self.queries = {lang: {} for lang in self.langs}\n",
    "    \n",
    "        for lang in self.langs:\n",
    "            for row in tqdm.tqdm(load_dataset('unicamp-dl/mmarco', f'queries-{lang}')['train'], desc=lang):\n",
    "                self.queries[lang][row['id']] = row['text']\n",
    "\n",
    "        #Get the passages\n",
    "        self.collections = {lang: load_dataset('unicamp-dl/mmarco', f'collection-{lang}')['collection'] for lang in self.langs}\n",
    "\n",
    "        #Get the triplets\n",
    "        # with gzip.open(self.triplets_path, 'rt') as fIn:\n",
    "        #     self.triplets = [json.loads(line) for line in tqdm.tqdm(fIn, desc=\"triplets\", total=502938)] \n",
    "        #     \"\"\"\n",
    "        #     self.triplets = []\n",
    "        #     for line in tqdm.tqdm(fIn):\n",
    "        #         self.triplets.append(json.loads(line))\n",
    "        #         if len(self.triplets) >= 1000:\n",
    "        #             break\n",
    "        #     \"\"\"\n",
    "\n",
    "        # asmita's paths\n",
    "        s = open(\"textbook_embeddings/fine_tune_cleaned_training_data.json\")\n",
    "        data = json.load(s)\n",
    "        df = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "        self.triplets = df[['query', 'pos_a', 'neg_a1', 'neg_a2', 'neg_a3']]\n",
    "\n",
    "        # self.bad_data = []\n",
    "        # for dataset in [third, fourth]:\n",
    "        #     for row in dataset:\n",
    "        #         self.bad_data.append(row['text'])\n",
    "\n",
    "        # # create tirplets+ of <question, good answer (pos), and 3 bad answers (neg1, neg2, neg3)>\n",
    "        # self.triplets = []\n",
    "        # for dataset in [first, second]:\n",
    "        #     for row in dataset:\n",
    "        #         itr_counter = 0 \n",
    "        #         # Ensure our negative samples are not the same as each other (and that neg not == pos sample)\n",
    "                \n",
    "        #         neg1, neg2, neg3, = random.choice(self.bad_data), random.choice(self.bad_data), random.choice(self.bad_data)\n",
    "        #         while ( neg1 == neg2 or neg1 == neg3 or neg2 == neg3 ) and ( any(neg_ex in row['GPT-3-Semantic-Search-Generations']['answer'] for neg_ex in [neg1, neg2, neg3]) ) and itr_counter < 50:\n",
    "        #             neg1, neg2, neg3, = random.choice(self.bad_data), random.choice(self.bad_data), random.choice(self.bad_data)\n",
    "        #             itr_counter += 1\n",
    "        #         if itr_counter == 50:\n",
    "        #             print(\"❌❌❌ WARNING: 50 iterations reached, negs may be equal ❌❌❌\")\n",
    "        #         self.triplets.append([row['GPT-3-Semantic-Search-Generations']['question'], row['GPT-3-Semantic-Search-Generations']['answer'],[neg1, neg2, neg3]])\n",
    "\n",
    "            \n",
    "        def collate_fn(self, batch):\n",
    "            '''\n",
    "            # EXPECED DATA FORMAT BEFORE TOKENIZATION\n",
    "            query_doc_pairs_OUR_INTERPRETATION = [\n",
    "                [('query1', 'pos1'), ('query2', 'po2')],\n",
    "                [('query1', 'neg1'), ('query2', 'neg2')],\n",
    "                [],\n",
    "                [],\n",
    "                []\n",
    "            ]\n",
    "            '''\n",
    "            #Create data for list-rank-loss\n",
    "            query_doc_pairs = [[] for _ in  range(1+3)]\n",
    "                \n",
    "            #example_train_data = [['query', 'pos', 'neg'],['query2', 'po2', 'neg2']]\n",
    "\n",
    "            # create a list of lists\n",
    "            query_doc_pairs = []\n",
    "            for row in batch.iterrows():\n",
    "                tmp_row = []\n",
    "                tmp_row.append(row[1]['query'])\n",
    "                tmp_row.append(row[1]['pos_a'])\n",
    "                tmp_row.append(row[1]['neg_a1'])\n",
    "                tmp_row.append(row[1]['neg_a2'])\n",
    "                tmp_row.append(row[1]['neg_a3'])\n",
    "\n",
    "                query_doc_pairs.append(tmp_row)\n",
    "\n",
    "                ''' \n",
    "                future refernece for multiple negs\n",
    "                # for num_neg, neg_id in enumerate(neg_ids):\n",
    "                    # query_doc_pairs[1+num_neg].append((query_text, row[2]))\n",
    "                '''\n",
    "\n",
    "            ''' ORIGINAL CODE\n",
    "            query_doc_pairs = [[] for _ in  range(1+self.num_negs)]\n",
    "            cross_lingual_batch = random.random() < self.cross_lingual_chance \n",
    "            for row in batch:\n",
    "                qid = row['qid']\n",
    "                print('qid', qid)\n",
    "                pos_id = random.choice(row['pos'])\n",
    "                query_lang = random.choice(self.langs)\n",
    "                query_text = self.queries[query_lang][qid]\n",
    "                    \n",
    "                doc_lang = random.choice(self.langs) if cross_lingual_batch else query_lang \n",
    "                query_doc_pairs[0].append((query_text, self.collections[doc_lang][pos_id]['text']))\n",
    "                dense_bm25_neg = list(set(row['dense_neg'] + row['bm25_neg']))\n",
    "                neg_ids = random.sample(dense_bm25_neg, self.num_negs)\n",
    "                for num_neg, neg_id in enumerate(neg_ids):\n",
    "                    doc_lang = random.choice(self.langs) if cross_lingual_batch else query_lang\n",
    "                    query_doc_pairs[1+num_neg].append((query_text, self.collections[doc_lang][neg_id]['text']))\n",
    "            '''\n",
    "            print(\"query_doc_pairs\", query_doc_pairs)\n",
    "        \n",
    "            #Now tokenize the data\n",
    "            features = [self.tokenizer(qd_pair, max_length=self.max_seq_length, padding=True, truncation='only_second', return_tensors=\"pt\") for qd_pair in query_doc_pairs]\n",
    "            \n",
    "            return features\n",
    "\n",
    "        def train_dataloader(self):\n",
    "            return DataLoader(self.triplets, shuffle=True, batch_size=self.train_batch_size, num_workers=1, pin_memory=True, collate_fn=self.collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListRankLoss(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        learning_rate: float = 2e-5,\n",
    "        warmup_steps: int = 1000,\n",
    "        weight_decay: float = 0.01,\n",
    "        train_batch_size: int = 32,\n",
    "        eval_batch_size: int = 32,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        print(self.hparams)\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(model_name, num_labels=1)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, config=self.config)\n",
    "        self.loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        self.global_train_step = 0\n",
    "        \n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        return self.model(**inputs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pred_scores = []\n",
    "        print(\"batch\", batch)\n",
    "        print(\"batch a 0\", batch[0])\n",
    "        scores = torch.tensor([0] * len(batch[0]['input_ids']), device=self.model.device)\n",
    "   \n",
    "        for feature in batch:\n",
    "            pred_scores.append(self(**feature).logits.squeeze())\n",
    "\n",
    "        pred_scores = torch.stack(pred_scores, 1)\n",
    "        loss_value = self.loss_fct(pred_scores, scores)\n",
    "        self.global_train_step += 1\n",
    "        self.log('global_train_step', self.global_train_step)\n",
    "        self.log(\"train/loss\", loss_value)\n",
    "\n",
    "        return loss_value\n",
    "     \n",
    "\n",
    "    def setup(self, stage=None) -> None:\n",
    "        if stage != \"fit\":\n",
    "            return\n",
    "        # Get dataloader by calling it - train_dataloader() is called after setup() by default\n",
    "        train_loader = self.trainer.datamodule.train_dataloader()\n",
    "\n",
    "        # Calculate total steps\n",
    "        tb_size = self.hparams.train_batch_size * max(1, self.trainer.gpus)\n",
    "        ab_size = self.trainer.accumulate_grad_batches\n",
    "        self.total_steps = (len(train_loader) // ab_size) * self.trainer.max_epochs\n",
    "\n",
    "        print(\"{tb_size=}\")\n",
    "        print(\"{ab_size=}\")\n",
    "        print(\"{len(train_loader)=}\")\n",
    "        print(\"{self.total_steps=}\")\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer =  torch.optim.AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate)\n",
    "\n",
    "        lr_scheduler = get_scheduler(\n",
    "            name=\"linear\",\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=self.hparams.warmup_steps,\n",
    "            num_training_steps=self.total_steps,\n",
    "        )\n",
    "\n",
    "        scheduler = {\"scheduler\": lr_scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    dm = MSMARCOData(\n",
    "        model_name=args.model,\n",
    "        langs=args.langs,\n",
    "        # triplets_path='./msmarco-hard-triplets.jsonl.gz',\n",
    "        triplets_path='./msmarco-triplets.jsonl.gz',\n",
    "        train_batch_size=args.batch_size,\n",
    "        cross_lingual_chance=args.cross_lingual_chance,\n",
    "        num_negs=args.num_negs\n",
    "    )\n",
    "    output_dir = f\"output/{args.model.replace('/', '-')}-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    print(\"Output_dir:\", output_dir)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"multilingual-cross-encoder\", name=output_dir.split(\"/\")[-1])\n",
    "\n",
    "    train_script_path = os.path.join(output_dir, 'train_script.py')\n",
    "    copyfile(__file__, train_script_path)\n",
    "    with open(train_script_path, 'a') as fOut:\n",
    "        fOut.write(\"\\n\\n# Script was called via:\\n#python \" + \" \".join(sys.argv))\n",
    "\n",
    "    \n",
    "    # saves top-K checkpoints based on \"val_loss\" metric\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        every_n_train_steps=25000,\n",
    "        save_top_k=5,\n",
    "        monitor=\"global_train_step\",\n",
    "        mode=\"max\",\n",
    "        dirpath=output_dir,\n",
    "        filename=\"ckpt-{global_train_step}\",\n",
    "    )\n",
    "\n",
    "\n",
    "    model = ListRankLoss(model_name=args.model)\n",
    "\n",
    "    trainer = Trainer(max_epochs=args.epochs, \n",
    "                      accelerator=\"gpu\", \n",
    "                      devices=args.num_gpus, \n",
    "                      precision=args.precision, \n",
    "                      strategy=args.strategy,    \n",
    "                      default_root_dir=output_dir,\n",
    "                      callbacks=[checkpoint_callback],\n",
    "                      logger=wandb_logger\n",
    "                      )\n",
    "\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "\n",
    "    #Save final HF model \n",
    "    final_path = os.path.join(output_dir, \"final\")\n",
    "    dm.tokenizer.save_pretrained(final_path)\n",
    "    model.model.save_pretrained(final_path)\n",
    "\n",
    "  \n",
    "def eval(args):\n",
    "    import ir_datasets\n",
    "    \n",
    " \n",
    "    model = ListRankLoss.load_from_checkpoint(args.ckpt)\n",
    "    hf_model = model.model.cuda()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model.hparams.model_name)\n",
    "\n",
    "    dev_qids = set()\n",
    "\n",
    "    dev_queries = {}\n",
    "    dev_rel_docs = {}\n",
    "    needed_pids = set()\n",
    "    needed_qids = set()\n",
    "\n",
    "    corpus = {}\n",
    "    retrieved_docs = {}\n",
    "\n",
    "    dataset = ir_datasets.load(\"msmarco-passage/dev/small\")\n",
    "    for query in dataset.queries_iter():\n",
    "        dev_qids.add(query.query_id)\n",
    "\n",
    "    \n",
    "    with open('data/qrels.dev.tsv') as fIn:\n",
    "        for line in fIn:\n",
    "            qid, _, pid, _ = line.strip().split('\\t')\n",
    "\n",
    "            if qid not in dev_qids:\n",
    "                continue\n",
    "\n",
    "            if qid not in dev_rel_docs:\n",
    "                dev_rel_docs[qid] = set()\n",
    "            dev_rel_docs[qid].add(pid)\n",
    "\n",
    "            retrieved_docs[qid] = set()\n",
    "            needed_qids.add(qid)\n",
    "            needed_pids.add(pid)\n",
    "\n",
    "    for query in dataset.queries_iter():\n",
    "        qid = query.query_id\n",
    "        if qid in needed_qids:\n",
    "            dev_queries[qid] = query.text\n",
    "\n",
    "    with open('data/top1000.dev', 'rt') as fIn:\n",
    "        for line in fIn:\n",
    "            qid, pid, query, passage = line.strip().split(\"\\t\")\n",
    "            corpus[pid] = passage\n",
    "            retrieved_docs[qid].add(pid)\n",
    "\n",
    "\n",
    "    ## Run evaluator\n",
    "    print(\"Queries: {}\".format(len(dev_queries)))\n",
    "\n",
    "    mrr_scores = []\n",
    "    hf_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for qid in tqdm.tqdm(dev_queries, total=len(dev_queries)):\n",
    "            query = dev_queries[qid]\n",
    "            top_pids = list(retrieved_docs[qid])\n",
    "            cross_inp = [[query, corpus[pid]] for pid in top_pids]\n",
    "\n",
    "            encoded = tokenizer(cross_inp, padding=True, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "            output = model(**encoded)\n",
    "            bert_score = output.logits.detach().cpu().numpy()\n",
    "            bert_score = np.squeeze(bert_score)\n",
    "        \n",
    "            argsort = np.argsort(-bert_score)\n",
    "\n",
    "            rank_score = 0\n",
    "            for rank, idx in enumerate(argsort[0:10]):\n",
    "                pid = top_pids[idx]\n",
    "                if pid in dev_rel_docs[qid]:\n",
    "                    rank_score = 1/(rank+1)\n",
    "                    break\n",
    "\n",
    "            mrr_scores.append(rank_score)\n",
    "        \n",
    "            if len(mrr_scores) % 10 == 0:\n",
    "                print(\"{} MRR@10: {:.2f}\".format(len(mrr_scores), 100*np.mean(mrr_scores)))\n",
    "\n",
    "    print(\"MRR@10: {:.2f}\".format(np.mean(mrr_scores)*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--num_gpus NUM_GPUS]\n",
      "                             [--batch_size BATCH_SIZE] [--epochs EPOCHS]\n",
      "                             [--strategy STRATEGY] [--model MODEL] [--eval]\n",
      "                             [--ckpt CKPT]\n",
      "                             [--cross_lingual_chance CROSS_LINGUAL_CHANCE]\n",
      "                             [--precision PRECISION] [--num_negs NUM_NEGS]\n",
      "                             [--langs LANGS [LANGS ...]]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/avd6/.local/share/jupyter/runtime/kernel-c5ebf186-8b76-4d30-be2b-55ad3db225e6.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--num_gpus\", type=int, default=1)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--strategy\", default=None)\n",
    "    parser.add_argument(\"--model\", default='facebook/contriever-msmarco')\n",
    "    parser.add_argument(\"--eval\", action=\"store_true\")\n",
    "    parser.add_argument(\"--ckpt\")\n",
    "    parser.add_argument(\"--cross_lingual_chance\", type=float, default=0.0)\n",
    "    parser.add_argument(\"--precision\", type=int, default=16)\n",
    "    parser.add_argument(\"--num_negs\", type=int, default=3)\n",
    "    parser.add_argument(\"--langs\", nargs=\"+\", default=['english']) #, 'chinese', 'french', 'german', 'indonesian', 'italian', 'portuguese', 'russian', 'spanish', 'arabic', 'dutch', 'hindi', 'japanese', 'vietnamese'\n",
    "    \n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.eval:\n",
    "        eval(args)\n",
    "    else:\n",
    "        main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f84259a3b330308de677e904dd70af8e4d9960a0b20e6e297421ba1b1b840763"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
