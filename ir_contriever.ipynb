{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ac1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05da11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')\n",
    "model = AutoModel.from_pretrained('facebook/contriever-msmarco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de81239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean pooling\n",
    "\n",
    "def mean_pooling(token_embeddings, mask):\n",
    "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78291dfa",
   "metadata": {},
   "source": [
    "Generating embeddings for paragraph level text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ff9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file\n",
    "\n",
    "f = open(\"paragraphs.json\")\n",
    "paragraph_data_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235a5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "\n",
    "def clean(text):\n",
    "    new_text = re.sub('\\n', '', text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data --> apply tokenizer --> apply model --> mean pooling --> embeddings --> store in list --> convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting json data to a list ---> contriever input is a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf38af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(paragraph_data_json)/100)\n",
    "embeddings_list = []\n",
    "for k in range(n):\n",
    "    \n",
    "    if(k==n):\n",
    "        start = k*100\n",
    "        end = (list(data.keys())[-1])\n",
    "    else:\n",
    "        start = k*100\n",
    "        end = k*100+99\n",
    "        \n",
    "    for i in range(start, end):\n",
    "        para = paragraph_data_json[str(i)]\n",
    "        para = clean(para)\n",
    "        tokenized_para = tokenizer(para, padding=True, truncation=True, return_tensors='pt')\n",
    "        output_para = model(**tokenized_para)\n",
    "        embeddings_para = mean_pooling(output_para[0], tokenized_para['attention_mask'])\n",
    "        numpy_embeddings = embeddings_para.detach().numpy()\n",
    "        embeddings_list.append(numpy_embeddings)\n",
    "\n",
    "embeddings_numpy = np.array(embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46792df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 1, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6cfb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_numpy = embeddings_numpy.reshape((1980, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c7e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings in a numpy file\n",
    "\n",
    "np.save('paragraph_embeddings', embeddings_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d1169",
   "metadata": {},
   "source": [
    "Generating embeddings for sentence level text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4329211",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = open(\"sentences.json\")\n",
    "sentence_data = json.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6938572",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(sentence_data)/100)\n",
    "embeddings_list_line = []\n",
    "for k in range(n):\n",
    "    \n",
    "    if(k==n):\n",
    "        start = k*100\n",
    "        end = (list(sentence_data.keys())[-1])\n",
    "    else:\n",
    "        start = k*100\n",
    "        end = k*100+99\n",
    "        \n",
    "    for i in range(start, end):\n",
    "        line = sentence_data[str(i)]\n",
    "        line = clean(line)\n",
    "        tokenized_line = tokenizer(line, padding=True, truncation=True, return_tensors='pt')\n",
    "        output_line = model(**tokenized_line)\n",
    "        embeddings_line = mean_pooling(output_line[0], tokenized_line['attention_mask'])\n",
    "        numpy_embeddings_line = embeddings_line.detach().numpy()\n",
    "        embeddings_list_line.append(numpy_embeddings_line)\n",
    "\n",
    "np_embeddings_line = np.array(embeddings_list_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67c2ac57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4158, 1, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_embeddings_line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8913f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_embeddings_line = np_embeddings_line.reshape((4158, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f29687c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sentence_embeddings', np_embeddings_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6936faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4158, 768)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_embeddings_line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7706fd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4158, 768)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_line_embeddings = np.load('sentence_embeddings.npy')\n",
    "saved_line_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e44fd",
   "metadata": {},
   "source": [
    "Generate section level embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa0b587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsec = open(\"sections.json\")\n",
    "section_data = json.load(fsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c05ad1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(section_data)/100)\n",
    "embeddings_list_section = []\n",
    "for k in range(n):\n",
    "    \n",
    "    if(k==n):\n",
    "        start = k*100\n",
    "        end = (list(section_data.keys())[-1])\n",
    "    else:\n",
    "        start = k*100\n",
    "        end = k*100+99\n",
    "        \n",
    "    for i in range(start, end):\n",
    "        section = section_data[str(i)]\n",
    "        section = clean(section)\n",
    "        tokenized_section = tokenizer(section, padding=True, truncation=True, return_tensors='pt')\n",
    "        output_section = model(**tokenized_section)\n",
    "        embeddings_section = mean_pooling(output_section[0], tokenized_section['attention_mask'])\n",
    "        numpy_embeddings_section = embeddings_section.detach().numpy()\n",
    "        embeddings_list_section.append(numpy_embeddings_section)\n",
    "\n",
    "np_embeddings_section = np.array(embeddings_list_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d71a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_embeddings_section = np_embeddings_section.reshape((99,768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d8fc8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 768)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_embeddings_section.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d8f5359",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('section_embeddings', np_embeddings_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbe52e",
   "metadata": {},
   "source": [
    "Encode questions and retrieve the most relevant sentences/paragraphs/sections\n",
    "    --> generate and test on your own sample questions for now\n",
    "    --> ask group for proper questions after testing above embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13562031",
   "metadata": {},
   "source": [
    "Retrieving most relevant section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0e912",
   "metadata": {},
   "source": [
    "Try to form and test better questions. Sentence and para matchings are weird."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
