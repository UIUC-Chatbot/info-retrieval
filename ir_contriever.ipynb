{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ac1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05da11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')\n",
    "model = AutoModel.from_pretrained('facebook/contriever-msmarco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de81239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean pooling\n",
    "\n",
    "def mean_pooling(token_embeddings, mask):\n",
    "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78291dfa",
   "metadata": {},
   "source": [
    "Generating embeddings for paragraph level text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ff9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file\n",
    "\n",
    "f = open(\"paragraphs.json\")\n",
    "paragraph_data_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235a5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "\n",
    "def clean(text):\n",
    "    new_text = re.sub('\\n', '', text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data --> apply tokenizer --> apply model --> mean pooling --> embeddings --> store in list --> convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting json data to a list ---> contriever input is a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff7eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_data = list(paragraph_data_json.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf38af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(paragraph_data_json)/100)\n",
    "embeddings_list = []\n",
    "for k in range(n):\n",
    "    \n",
    "    if(k==n):\n",
    "        start = k*100\n",
    "        end = (list(data.keys())[-1])\n",
    "    else:\n",
    "        start = k*100\n",
    "        end = k*100+99\n",
    "        \n",
    "    for i in range(start, end):\n",
    "        para = paragraph_data_json[str(i)]\n",
    "        para = clean(para)\n",
    "        tokenized_para = tokenizer(para, padding=True, truncation=True, return_tensors='pt')\n",
    "        output_para = model(**tokenized_para)\n",
    "        embeddings_para = mean_pooling(output_para[0], tokenized_para['attention_mask'])\n",
    "        numpy_embeddings = embeddings_para.detach().numpy()\n",
    "        embeddings_list.append(numpy_embeddings)\n",
    "        #embeddings_list.append(embeddings_para)\n",
    "\n",
    "embeddings_numpy = np.array(embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46792df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 768)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6cfb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_numpy = embeddings_numpy.reshape((1980, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52c7e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings in a numpy file\n",
    "\n",
    "np.save('paragraph_embeddings', embeddings_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d1169",
   "metadata": {},
   "source": [
    "Generating embeddings for sentence level text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4329211",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = open(\"sentences.json\")\n",
    "sentence_data = json.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6938572",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(sentence_data)/100)\n",
    "embeddings_list_line = []\n",
    "for k in range(n):\n",
    "    \n",
    "    if(k==n):\n",
    "        start = k*100\n",
    "        end = (list(sentence_data.keys())[-1])\n",
    "    else:\n",
    "        start = k*100\n",
    "        end = k*100+99\n",
    "        \n",
    "    for i in range(start, end):\n",
    "        line = sentence_data[str(i)]\n",
    "        line = clean(line)\n",
    "        tokenized_line = tokenizer(line, padding=True, truncation=True, return_tensors='pt')\n",
    "        output_line = model(**tokenized_line)\n",
    "        embeddings_line = mean_pooling(output_line[0], tokenized_line['attention_mask'])\n",
    "        numpy_embeddings_line = embeddings_line.detach().numpy()\n",
    "        embeddings_list_line.append(numpy_embeddings_line)\n",
    "\n",
    "np_embeddings_line = np.array(embeddings_list_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67c2ac57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4158, 1, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_embeddings_line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8913f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_embeddings_line = np_embeddings_line.reshape((4158, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f29687c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sentence_embeddings', np_embeddings_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6936faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4158, 768)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_embeddings_line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7706fd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4158, 768)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_line_embeddings = np.load('sentence_embeddings.npy')\n",
    "saved_line_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e44fd",
   "metadata": {},
   "source": [
    "Generate section level embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa0b587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsec = open(\"sections.json\")\n",
    "section_data = json.load(fsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c05ad1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(section_data)/100)\n",
    "embeddings_list_section = []\n",
    "for k in range(n):\n",
    "    \n",
    "    if(k==n):\n",
    "        start = k*100\n",
    "        end = (list(section_data.keys())[-1])\n",
    "    else:\n",
    "        start = k*100\n",
    "        end = k*100+99\n",
    "        \n",
    "    for i in range(start, end):\n",
    "        section = section_data[str(i)]\n",
    "        section = clean(section)\n",
    "        tokenized_section = tokenizer(section, padding=True, truncation=True, return_tensors='pt')\n",
    "        output_section = model(**tokenized_section)\n",
    "        embeddings_section = mean_pooling(output_section[0], tokenized_section['attention_mask'])\n",
    "        numpy_embeddings_section = embeddings_section.detach().numpy()\n",
    "        embeddings_list_section.append(numpy_embeddings_section)\n",
    "\n",
    "np_embeddings_section = np.array(embeddings_list_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d71a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_embeddings_section = np_embeddings_section.reshape((99,768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d8fc8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 768)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_embeddings_section.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d8f5359",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('section_embeddings', np_embeddings_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbe52e",
   "metadata": {},
   "source": [
    "Encode questions and retrieve the most relevant sentences/paragraphs/sections\n",
    "    --> generate and test on your own sample questions for now\n",
    "    --> ask group for proper questions after testing above embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13562031",
   "metadata": {},
   "source": [
    "Retrieving most relevant section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8c6483c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_section_embeddings = np.load('section_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "27afd235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_section_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d6e69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_tensors = torch.from_numpy(saved_section_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "70c7070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['What is a procedure?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e52acdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_question = tokenizer(questions[0], padding=True, truncation=True, return_tensors='pt')\n",
    "output_question = model(**tokenized_question)\n",
    "embeddings_question = mean_pooling(output_question[0], tokenized_question['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d36c188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 768)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_section_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "651c3e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(section_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4e55283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_section = {}\n",
    "for i in range(len(section_tensors)):\n",
    "    dot_product_section[embeddings_question[0]@section_tensors[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac959234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "max_prod_tensor = max(dot_product_section.keys())\n",
    "print(dot_product_section[max_prod_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "49a7fb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{Procedure and System Calls*}\\n\\nA { procedure} is a sequence of instructions that executes a\\nparticular task.  Procedures are used as building blocks for multiple,\\nlarger tasks.  The concept of a procedure is fundamental to\\nprogramming, and appears in some form in every high-level language as\\nwell as in most ISAs.\\n\\nFor our purposes, the terms procedure, subroutine,\\nfunction, and method are synonymous, although they usually have\\nslightly different meanings from the linguistic point of view.\\nProcedure calls are supported through { call} and { return}\\ncontrol flow instructions.  The first instruction in the code below,\\nfor example, transfers control to the procedure ``DoSomeWork,'' which\\npresumably does some work, then returns control to the instruction\\nfollowing the call.\\n\\n{-6pt}\\n\\n=DoSomeWork:WW=WWWW=DoSomeWorkWW= \\n>loop:>CALL>DoSomeWork\\n>>CMP>R6,#1>; compare return value in R6 to 1\\n>>BEQ>loop>; keep doing work until R6 is not 1\\n\\n>DoSomeWork:>>> ; set R6 to 0 when all work is done, 1 otherwise \\n>>RETN\\n\\n{-6pt}\\n\\nThe procedure also places a return value in R6, which the instruction\\nfollowing the call compares with immediate value 1.  Until the two are\\nnot equal (when all work is done), the branch returns control to the\\ncall and executes the procedure again.\\n\\nAs you may recall, the call and return use the stack pointer to keep\\ntrack of nested calls.  Sample RTL for these operations appears below.\\n\\n\\n{eqnarray*}\\n{call RTL}&&SP  SP - 1\\n&& M[SP]  PC\\n&& PC  {procedure start}\\n{eqnarray*}\\n\\n\\n{eqnarray*}\\n{return RTL}&&PC  M[SP]\\n&&SP  SP + 1\\n{eqnarray*}\\n\\n\\nWhile an ISA provides the call and return instructions necessary to\\nsupport procedures, it does not specify how information is passed to\\nor returned from a procedure.  A standard for such decisions is\\nusually developed and included in descriptions of the architecture,\\nhowever.  This { calling convention} specifies how information is\\npassed between a caller and a callee.  In particular, it specifies the\\nfollowing: where arguments must be placed, either in registers or in\\nspecific stack memory locations; which registers can be used or\\nchanged by the procedure; and where any return value must be placed.\\n\\nThe term ``calling convention'' is also used in the programming\\nlanguage community to describe the convention for deciding what\\ninformation is passed for a given call operation.  For example, are\\nvariables passed by value, by pointers to values, or in some other\\nway?  However, once the things to be sent are decided, the\\narchitectural calling convention that we discuss here is used\\nto determine where to put the data in order for the callee to be able\\nto find it.\\n\\nCalling conventions for architectures with large register sets\\ntypically pass arguments in registers, and nearly all conventions\\nplace the return value in a register.  A calling convention also\\ndivides the register set into { caller-saved} and \\n{ callee-saved} registers.  Caller-saved registers can be modified \\narbitrarily\\nby the called procedure, whereas any value in a callee-saved register\\nmust be preserved.  Similarly, before calling a procedure, a caller\\nmust preserve the values of any caller saved registers that are needed\\nafter the call.  Registers of both types usually saved on the stack by\\nthe appropriate code (caller or callee).\\n\\n\\n\\n\\n\\nA typical stack structure appears in the figure to the right.  In\\npreparation for a call, a caller first stores any caller-saved\\nregisters on the stack.  Arguments to the procedure to be called are\\npushed next.  The procedure is called next, implicitly pushing the\\nreturn address (the address of the instruction following the call\\ninstruction).  Finally, the called procedure may allocate space on the\\nstack for storage of callee-saved registers as well as local\\nvariables.\\n\\nAs an example, the following calling convention can be applied to \\nan {8-register} load-store architecture similar to the {LC-3}\\nISA: the first three arguments must be placed in R0 through R2 (in order), \\nwith any remaining arguments on the stack; the return value must be placed \\nin R6; R0 through R2 are caller-saved, as\\nis R6, while R3 through R5 are callee-saved; R7 is used as the stack\\npointer.  The code fragments below use this calling convention to\\nimplement a procedure and a call of that procedure.\\n\\n\\n{file=part4/figs/lec23-2.eps,width=1.25in}\\n\\n\\n[t]\\n{\\n[t]\\n\\nint =add3 (int n1, int n2, int n3) {\\n>return (n1 + n2 + n3);\\n}\\n\\nprintf (``d'', add3 (10, 20, 30));\\n\\n\\n\\nby convention:\\n= n1 is in R0\\n>n2 is in R1\\n>n3 is in R2\\n>return value is in R6\\n\\n\\n\\n[t]\\n\\nadd3:  = WWWW= WWWWW= \\nadd3:>ADD>R0,R0,R1\\n>ADD>R6,R0,R2\\n>RETN\\n>\\n>PUSH>R1>; save the value in R1\\n>LDI>R0,#10>; marshal arguments\\n>LDI>R1,#20\\n>LDI>R2,#30\\n>CALL>add3\\n>MOV>R1,R6>; return value becomes 2nd argument\\n>LDI>R0,``d''>; load a pointer to the string\\n>CALL>printf\\n>POP>R1>; restore R1\\n\\n\\n\\nThe add3 procedure takes three integers as arguments, adds them\\ntogether, and returns the sum.  The procedure is called with the\\nconstants 10, 20, and 30, and the result is printed.  By the calling\\nconvention, when the call is made, R0 must contain the value 10, R1\\nthe value 20, and R2 the value 30.  We assume that the caller wants to\\npreserve the value of R1, but does not care about R3 or R5.  In the\\nassembly language version on the right, R1 is first saved to the\\nstack, then the arguments are marshaled into position, and finally the\\ncall is made.  The procedure itself needs no local storage and does\\nnot change any callee-saved registers, thus must simply add the\\nnumbers together and place the result in R6.  After add3 returns, its\\nreturn value is moved from R6 to R1 in preparation for the call to\\nprintf.  After loading a pointer to the format string into R0, the\\nsecond call is made, and R1 is restored, completing the translation.\\n\\n{ System calls} are almost identical to procedure calls.  As with\\nprocedure calls, a calling convention is used: before invoking a\\nsystem call, arguments are marshaled into the appropriate registers or\\nlocations in the stack; after a system call returns, any result\\nappears in a pre-specified register.  The calling convention used for\\nsystem calls need not be the same as that used for procedure calls.\\nRather than a call instruction, system calls are usually initiated\\nwith a { trap} instruction, and system calls are also known as\\ntraps.  With many architectures, a system call places the processor in\\nprivileged or kernel mode, and the instructions that implement the\\ncall are considered to be part of the operating system.  The term\\nsystem call arises from this fact.\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_data['50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0ee1ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_para_embeddings = np.load('paragraph_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "99bd8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_tensors = torch.from_numpy(saved_para_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1776a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_para = {}\n",
    "for i in range(len(para_tensors)):\n",
    "    dot_product_para[embeddings_question[0]@para_tensors[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7e3a0ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688\n"
     ]
    }
   ],
   "source": [
    "max_para_tensor = max(dot_product_para.keys())\n",
    "print(dot_product_para[max_para_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "514781b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The { zero register} appears in modern architectures of the RISC\\nvariety (defined in the next section of these notes).  The register is\\nread-only and serves both as a useful constant and as a destination\\nfor operations performed only for their side-effects (for example, setting\\nstatus bits).  The availability of a zero register also allows certain\\nopcodes to serve double duty.  A register-to-register add instruction\\nbecomes a register move instruction when one source operand is zero.\\nSimilarly, an immediate add instruction becomes an immediate load\\ninstruction when one source operand is zero.'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_data_json[str(688)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ae5decf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_sentence_embeddings = np.load('sentence_embeddings.npy')\n",
    "sentence_tensors = torch.from_numpy(saved_sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "498d1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_sentence = {}\n",
    "for i in range(len(sentence_tensors)):\n",
    "    dot_product_sentence[embeddings_question[0]@sentence_tensors[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e560795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "max_sentence_tensor = max(dot_product_sentence.keys())\n",
    "print(dot_product_sentence[max_sentence_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b298ccb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"''\\n\\nThe impact of increasingly dense integrated circuit technology had\\nbegun to have its effect, however, and in view of increasing processor\\nclock speeds, more and more programmers were using high-level\\nlanguages rather than writing assembly code.\""
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_data['1500']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0e912",
   "metadata": {},
   "source": [
    "Try to form and test better questions. Sentence and para matchings are weird."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
