{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ef8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01462e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')\n",
    "model = AutoModel.from_pretrained('facebook/contriever-msmarco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01ad4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(token_embeddings, mask):\n",
    "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ee1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"paragraphs.json\")\n",
    "para_data = json.load(fp)\n",
    "\n",
    "fsec = open(\"sections.json\")\n",
    "section_data = json.load(fsec)\n",
    "\n",
    "fs = open(\"sentences.json\")\n",
    "sentence_data = json.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7bf452",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_section_embeddings = np.load('section_embeddings.npy')\n",
    "saved_para_embeddings = np.load('paragraph_embeddings.npy')\n",
    "saved_sentence_embeddings = np.load('sentence_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d3ee459",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_tensors = torch.from_numpy(saved_section_embeddings)\n",
    "para_tensors = torch.from_numpy(saved_para_embeddings)\n",
    "sentence_tensors = torch.from_numpy(saved_sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9279f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "2078\n",
      "4243\n"
     ]
    }
   ],
   "source": [
    "print(len(section_data))\n",
    "print(len(para_data))\n",
    "print(len(sentence_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d81d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "\n",
    "def clean(text):\n",
    "    new_text = re.sub('\\n', '', text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6a042",
   "metadata": {},
   "source": [
    "Extracting questions from the gpt-3 sections data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af20f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the gpt-3 data\n",
    "\n",
    "fq = open(\"../data-generator/gpt-3/GPT-3_section_level.json\")\n",
    "gpt3_section_data = json.load(fq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7091c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with section number as key and question as value\n",
    "\n",
    "qc_section_dict = {}\n",
    "for i in range(len(gpt3_section_data)):\n",
    "    clean_question = clean(gpt3_section_data[i]['questions'][4:])\n",
    "    qc_section_dict[i] = clean_question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d0599",
   "metadata": {},
   "source": [
    "Retrieving most relevant section, paragraph, and sentence from saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95d3b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves the section with highest dot product with the question\n",
    "\n",
    "def section_retriever(embedded_question):\n",
    "    section_scores = {}\n",
    "    for i in range(len(section_tensors)):\n",
    "        score = embedded_question[0]@section_tensors[i]\n",
    "        section_scores[i] = score\n",
    "    \n",
    "    highest_score = max(section_scores, key=section_scores.get)\n",
    "    return highest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cae5acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves the paragraph with highest dot product with the question\n",
    "\n",
    "def paragraph_retriever(embedded_question):\n",
    "    para_scores = {}\n",
    "    for i in range(len(para_tensors)):\n",
    "        score = embedded_question[0]@para_tensors[i]\n",
    "        para_scores[i] = score\n",
    "    \n",
    "    highest_score = max(para_scores, key=para_scores.get)\n",
    "    return highest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff9dc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves the sentence with highest dot product with the question\n",
    "\n",
    "def sentence_retriever(embedded_question):\n",
    "    sentence_scores = {}\n",
    "    for i in range(len(sentence_tensors)):\n",
    "        score = embedded_question[0]@sentence_tensors[i]\n",
    "        sentence_scores[i] = score\n",
    "    \n",
    "    highest_score = max(sentence_scores, key=sentence_scores.get)\n",
    "    return highest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c2d5888",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating a dataframe with highest section/paragraph/sentence level scores for all questions\n",
    "\n",
    "cols = ['Question', 'GPT-3 Section', 'Section', 'Paragraph', 'Sentence']\n",
    "score_data = []\n",
    "\n",
    "for j in qc_section_dict:\n",
    "    question = qc_section_dict[j]\n",
    "    \n",
    "    #embed the question\n",
    "    tokenized_question = tokenizer(question, padding=True, truncation=True, return_tensors='pt')\n",
    "    output_question = model(**tokenized_question)\n",
    "    embeddings_question = mean_pooling(output_question[0], tokenized_question['attention_mask'])\n",
    "    \n",
    "    # retrieve section/para/sentence\n",
    "    section_no = section_retriever(embeddings_question)\n",
    "    paragraph_no = paragraph_retriever(embeddings_question)\n",
    "    sentence_no = sentence_retriever(embeddings_question)\n",
    "    \n",
    "    # store the question no., question, and scores in a dataframe\n",
    "    row = [question, j, section_no, paragraph_no, sentence_no]\n",
    "    score_data.append(row)\n",
    "\n",
    "score_df = pd.DataFrame(score_data, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64c503fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>GPT-3 Section</th>\n",
       "      <th>Section</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the design process for a digital FSM ...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is it important to design digital systems ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>845</td>\n",
       "      <td>1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a Gray code?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does a three-bit gray code counter work?</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it possible to create a counter with fewer ...</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>What is the meaning of the term \"universal com...</td>\n",
       "      <td>139</td>\n",
       "      <td>60</td>\n",
       "      <td>1687</td>\n",
       "      <td>3636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>What is the overflow condition for unsigned ad...</td>\n",
       "      <td>140</td>\n",
       "      <td>73</td>\n",
       "      <td>1398</td>\n",
       "      <td>3046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Why is the converse of an implication not alwa...</td>\n",
       "      <td>141</td>\n",
       "      <td>81</td>\n",
       "      <td>1571</td>\n",
       "      <td>4119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>-Why is it important to know when an addition ...</td>\n",
       "      <td>142</td>\n",
       "      <td>53</td>\n",
       "      <td>1397</td>\n",
       "      <td>4124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>If A and B are both positive and S is negative...</td>\n",
       "      <td>143</td>\n",
       "      <td>81</td>\n",
       "      <td>1402</td>\n",
       "      <td>3050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  GPT-3 Section  \\\n",
       "0    How does the design process for a digital FSM ...              0   \n",
       "1    Why is it important to design digital systems ...              1   \n",
       "2                                 What is a Gray code?              2   \n",
       "3         How does a three-bit gray code counter work?              3   \n",
       "4    Is it possible to create a counter with fewer ...              4   \n",
       "..                                                 ...            ...   \n",
       "139  What is the meaning of the term \"universal com...            139   \n",
       "140  What is the overflow condition for unsigned ad...            140   \n",
       "141  Why is the converse of an implication not alwa...            141   \n",
       "142  -Why is it important to know when an addition ...            142   \n",
       "143  If A and B are both positive and S is negative...            143   \n",
       "\n",
       "     Section  Paragraph  Sentence  \n",
       "0         28        371         1  \n",
       "1          1        845      1883  \n",
       "2          2         12      2600  \n",
       "3          2        124       225  \n",
       "4         41         30        59  \n",
       "..       ...        ...       ...  \n",
       "139       60       1687      3636  \n",
       "140       73       1398      3046  \n",
       "141       81       1571      4119  \n",
       "142       53       1397      4124  \n",
       "143       81       1402      3050  \n",
       "\n",
       "[144 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "740fe3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the section level retrievals not matching with GPT-3 data\n",
    "\n",
    "sections_not_match = score_df.loc[~(score_df['GPT-3 Section'] == score_df['Section'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e14effc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question         How does the design process for a digital FSM ...\n",
       "GPT-3 Section                                                    0\n",
       "Section                                                         28\n",
       "Paragraph                                                      371\n",
       "Sentence                                                         1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0249a95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does the design process for a digital FSM work?\n",
      "-------------\n",
      "{Finite State Machine Design Examples, Part I}\n",
      "\n",
      "This set of notes uses a series of examples to illustrate design principles \n",
      "for the implementation of finite state machines (FSMs) using digital logic.\n",
      "We begin with an overview of the design process for a digital FSM, from\n",
      "the development of an abstract model through the implementation of\n",
      "functions for the next-state variables and output signals.\n",
      "Our first few examples cover only the concrete aspects:\n",
      "we implement several counters, which illustrate the basic \n",
      "process of translating a concrete and complete state transition diagram\n",
      "into an implementation based on flip-flops and logic gates.\n",
      "We next consider a counter with a number of states that is not a power of\n",
      "two, with which we illustrate the need for FSM initialization.\n",
      " As part of solving the initialization problem, we also introduce \n",
      " a general form of selection logic called a multiplexer.\n",
      "\n",
      "We then consider the design process as a whole through a more general\n",
      "example of a counter with multiple inputs to control its behavior. \n",
      "We work from\n",
      "an abstract model down to an implementation, illustrating how semantic\n",
      "knowledge from the abstract model can be used to simplify the \n",
      "implementation.  Finally, we illustrate how the choice of representation\n",
      "for the FSM's internal state affects the complexity of the implementation.\n",
      "Fortunately, designs that are more intuitive and easier for humans to\n",
      "understand also typically make the best designs in terms of \n",
      "other metrics, such as logic complexity.\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "SECTION: {From FSM to Computer}\n",
      "\n",
      "The FSM designs we have explored so far have started with a human-based\n",
      "design process in which someone writes down the desired behavior in\n",
      "terms of states, inputs, outputs, and transitions.  Such an approach\n",
      "makes it easier to build a digital FSM, since the abstraction used\n",
      "corresponds almost directly to the implementation.\n",
      "\n",
      "As an alternative, one can start by mapping the desired task into a\n",
      "high-level programming language, then using components such as registers,\n",
      "counters, and memories to implement the variables needed.  In this approach,\n",
      "the control structure of the code maps into a high-level FSM design.\n",
      "Of course, in order to implement our FSM with digital logic, we eventually\n",
      "still need to map down to bits and gates.\n",
      "\n",
      "In this set of notes, we show how one can transform a piece of code\n",
      "written in a high-level language into an FSM.  This process is meant to\n",
      "help you understand how we can design an FSM that executes simple\n",
      "pieces of a flow chart such as assignments, { if} statements, and \n",
      "loops.  Later, we generalize this concept and build an FSM that allows\n",
      "the pieces to be executed to be specified after the FSM is built---in \n",
      "other words, the FSM executes a program specified by bits stored in \n",
      "memory.  This more general model, as you might have already guessed, \n",
      "is a computer.  \n",
      "\n",
      "\n",
      "-------------\n",
      "PARAGRAPH: What does F do?  Analyzing the gates that produce it gives \n",
      "F=S_1S_0{V^+{S_1}S_0{V^.  If we \n",
      "ignore the two states outside of the main loop for S, the first term \n",
      "is 1 only when the lights are green on the East and West roads and the \n",
      "detector for the North and South roads indicates that no vehicles are \n",
      "approaching.  Similarly, the second term is 1 only when the lights are \n",
      "green on the North and South roads and the detector for the East and \n",
      "West roads indicates that no vehicles are approaching.\n",
      "-------------\n",
      "SENTENCE:  \n",
      "We begin with an overview of the design process for a digital FSM, from\n",
      "the development of an abstract model through the implementation of\n",
      "functions for the next-state variables and output signals.\n"
     ]
    }
   ],
   "source": [
    "print(score_df.loc[0]['Question'])\n",
    "print(\"-------------\")\n",
    "print(gpt3_section_data[score_df.loc[0]['GPT-3 Section']]['positive_ctxs']['text'])\n",
    "print(\"-------------\")\n",
    "print(\"SECTION:\", section_data[str(score_df.loc[0]['Section'])])\n",
    "print(\"-------------\")\n",
    "print(\"PARAGRAPH:\", para_data[str(score_df.loc[0]['Paragraph'])])\n",
    "print(\"-------------\")\n",
    "print(\"SENTENCE: \", sentence_data[str(score_df.loc[0]['Sentence'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7254d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question         Why is it important to design digital systems ...\n",
      "GPT-3 Section                                                    1\n",
      "Section                                                          1\n",
      "Paragraph                                                      845\n",
      "Sentence                                                      1883\n",
      "Name: 1, dtype: object\n",
      "-------------\n",
      "Why is it important to design digital systems that are compatible with other digital systems?\n",
      "-------------\n",
      "{Finite State Machine Design Examples, Part I}\n",
      "\n",
      "This set of notes uses a series of examples to illustrate design principles \n",
      "for the implementation of finite state machines (FSMs) using digital logic.\n",
      "We begin with an overview of the design process for a digital FSM, from\n",
      "the development of an abstract model through the implementation of\n",
      "functions for the next-state variables and output signals.\n",
      "Our first few examples cover only the concrete aspects:\n",
      "we implement several counters, which illustrate the basic \n",
      "process of translating a concrete and complete state transition diagram\n",
      "into an implementation based on flip-flops and logic gates.\n",
      "We next consider a counter with a number of states that is not a power of\n",
      "two, with which we illustrate the need for FSM initialization.\n",
      " As part of solving the initialization problem, we also introduce \n",
      " a general form of selection logic called a multiplexer.\n",
      "\n",
      "We then consider the design process as a whole through a more general\n",
      "example of a counter with multiple inputs to control its behavior. \n",
      "We work from\n",
      "an abstract model down to an implementation, illustrating how semantic\n",
      "knowledge from the abstract model can be used to simplify the \n",
      "implementation.  Finally, we illustrate how the choice of representation\n",
      "for the FSM's internal state affects the complexity of the implementation.\n",
      "Fortunately, designs that are more intuitive and easier for humans to\n",
      "understand also typically make the best designs in terms of \n",
      "other metrics, such as logic complexity.\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "SECTION: {Steps in the Design Process}\n",
      "\n",
      "Before we begin exploring designs, let's talk briefly about the general\n",
      "approach that we take when designing an FSM.  We follow a six-step\n",
      "process:{-8pt}\n",
      "\n",
      "{{}{}\n",
      "{}{}{}\n",
      "{develop an abstract model}{step-abs}\n",
      "{specify I/O behavior}{step-io}\n",
      "{complete the specification}{step-complete}\n",
      "{choose a state representation}{step-repn}\n",
      "{calculate logic expressions}{step-logic}\n",
      "{implement with flip-flops and gates}{step-gates}\n",
      "}\n",
      "{-8pt}\n",
      "\n",
      "In Step {step-abs}, we translate our description in human language\n",
      "into a model with states and desired behavior.  At this stage, we \n",
      "simply try to capture the intent of the description and are not\n",
      "particularly thorough nor exact.\n",
      "\n",
      "Step {step-io} begins to formalize the model, starting with its\n",
      "input and output behavior.  If we eventually plan to develop an\n",
      "implementation of our FSM as a digital system (which is not the \n",
      "only choice, of course!), all input and output\n",
      "must consist of bits.  Often, input and/or output specifications\n",
      "may need to match other digital systems to which we plan to connect\n",
      "our FSM.  In fact, { most problems in developing large digital systems\n",
      "today arise because of incompatibilities when composing two or more\n",
      "separately designed pieces} (or { modules}) into an integrated system.\n",
      "\n",
      "Once we know the I/O behavior for our FSM, in Step {step-complete}\n",
      "we start to make\n",
      "any implicit assumptions clear and to make any other decisions\n",
      "necessary to the design.  Occasionally, we may choose to leave\n",
      "something undecided in the hope of simplifying the design with\n",
      "``don't care'' entries in the logic formulation.\n",
      "\n",
      "In Step {step-repn}, we select an internal representation\n",
      "for the bits necessary to encode the state of our FSM.  In practice,\n",
      "for small designs, this representation can be selected by a computer \n",
      "in such a way as to optimize the implementation.  However, for large\n",
      "designs, such as the LC-3 instruction set architecture that we\n",
      "study later in this class, humans do most of the work by hand.\n",
      "\n",
      "In the later examples in this set of notes, we show how even a \n",
      "small design can\n",
      "leverage meaningful information from the design when selecting\n",
      "the representation, leading to an implementation that is simpler\n",
      "and is easier to build correctly.\n",
      "\n",
      "We also show how one can\n",
      "use abstraction to simplify an implementation.\n",
      "\n",
      "By Step {step-logic}, our design is a complete specification in\n",
      "terms of bits, and we need merely derive logic expressions for the\n",
      "next-state variables and the output signals.  This process is no\n",
      "different than for combinational logic, and should already be fairly \n",
      "familiar to you.\n",
      "\n",
      "\n",
      "\n",
      "Finally, in Step {step-gates}, we translate our logic expressions\n",
      "into gates and use flip-flops (or registers) to hold the internal\n",
      "state bits of the FSM.  In later notes, we use more complex\n",
      "building blocks when implementing an FSM, building up abstractions\n",
      "in order to simplify the design process in much the same way that\n",
      "we have shown for combinational logic.\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "PARAGRAPH: Let's consider a few example of representations with unused patterns.\n",
      "Historically, one common class of representations of this type was \n",
      "those used to represent individual decimal digits.  We examine three\n",
      "examples from this class.\n",
      "-------------\n",
      "SENTENCE:    Since we have 10 decimal digits, we need \n",
      "10 patterns, and four bits for each digit.\n"
     ]
    }
   ],
   "source": [
    "print(score_df.loc[1])\n",
    "print(\"-------------\")\n",
    "print(score_df.loc[1]['Question'])\n",
    "print(\"-------------\")\n",
    "print(gpt3_section_data[score_df.loc[0]['GPT-3 Section']]['positive_ctxs']['text'])\n",
    "print(\"-------------\")\n",
    "print(\"SECTION:\", section_data[str(score_df.loc[1]['Section'])])\n",
    "print(\"-------------\")\n",
    "print(\"PARAGRAPH:\", para_data[str(score_df.loc[1]['Paragraph'])])\n",
    "print(\"-------------\")\n",
    "print(\"SENTENCE: \", sentence_data[str(score_df.loc[1]['Sentence'])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
