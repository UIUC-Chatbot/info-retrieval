{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72a61f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f16bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the class\n",
    "\n",
    "class ContrieverCB:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def clean(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Function to remove newline from text.\n",
    "        :param text: input string\n",
    "        :return: string without newline\n",
    "        \"\"\"\n",
    "        new_text = re.sub('\\n', '', text)\n",
    "        return new_text\n",
    "    \n",
    "    \n",
    "    def mean_pooling(self, token_embeddings, mask):\n",
    "        \"\"\"\n",
    "        Function to be used after model is applied to tokenized text to generate embeddings.\n",
    "        Used in the HuggingFace version.\n",
    "        :param token_embeddings: output of model\n",
    "        :param mask: attention mask of the tokens\n",
    "        :return: tensors of the text\n",
    "        \"\"\"\n",
    "        token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "        sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "        return sentence_embeddings\n",
    "    \n",
    "    \n",
    "    def generate_embeddings(self, path_to_json: str, path_to_output: str) -> None:\n",
    "        \"\"\"\n",
    "        Function takes input json filepath, generates numpy embeddings of the file and\n",
    "        saves them at the given output filepath.\n",
    "        :param path_to_json: input filepath\n",
    "        :param path_to_output: output filepath\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')\n",
    "        model = AutoModel.from_pretrained('facebook/contriever-msmarco')\n",
    "        \n",
    "        # open and read the input json file\n",
    "        file = open(path_to_json)\n",
    "        json_data = json.load(file)\n",
    "        \n",
    "        n = int(len(json_data)/100)\n",
    "        embeddings_list = []\n",
    "        \n",
    "        # take 100 units at a time and process it\n",
    "        for k in range(n):\n",
    "            if k==n:\n",
    "                start = k*100\n",
    "                end = (list(json_data.keys())[-1])\n",
    "            else:\n",
    "                start = k*100\n",
    "                end = k*100+99\n",
    "                \n",
    "            for i in range(start, end):\n",
    "                text = json_data[str(i)]\n",
    "                text = self.clean(text)\n",
    "                tokenized_text = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "                output = model(**tokenized_text)\n",
    "                embeddings = self.mean_pooling(output[0], tokenized_text['attention_mask'])\n",
    "                embeddings_np = embeddings.detach().numpy()\n",
    "                embeddings_list.append(embeddings_np)\n",
    "                \n",
    "        # convert embeddings list to numpy array\n",
    "        embeddings_array = np.array(embeddings_list)\n",
    "        \n",
    "        # reshape the numpy array\n",
    "        x = embeddings_array.shape[0]\n",
    "        y = embeddings_array.shape[2]\n",
    "        embeddings_array.reshape((x,y))\n",
    "        \n",
    "        # save the embeddings in a numpy file\n",
    "        filename = path_to_json.split('\\\\')[-1].split('.')[0]\n",
    "        filepath = os.path.join(path_to_output, filename)\n",
    "\n",
    "        np.save(filepath, embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f81b9d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "99\n",
      "100\n",
      "199\n",
      "200\n",
      "299\n",
      "300\n",
      "399\n",
      "400\n",
      "499\n",
      "500\n",
      "599\n",
      "600\n",
      "699\n",
      "700\n",
      "799\n",
      "800\n",
      "899\n",
      "900\n",
      "999\n",
      "1000\n",
      "1099\n",
      "1100\n",
      "1199\n",
      "1200\n",
      "1299\n",
      "1300\n",
      "1399\n",
      "1400\n",
      "1499\n",
      "1500\n",
      "1599\n",
      "1600\n",
      "1699\n",
      "1700\n",
      "1799\n",
      "1800\n",
      "1899\n",
      "1900\n",
      "1999\n",
      "paragraphs\n",
      "F:\\MSIM\\Sem 3\\Independent Study\\Projects\\embeddings\\paragraphs\n"
     ]
    }
   ],
   "source": [
    "input_path = 'F:\\MSIM\\Sem 3\\Independent Study\\Projects\\data-generator\\split_textbook\\paragraphs.json'\n",
    "output_path = 'F:\\MSIM\\Sem 3\\Independent Study\\Projects\\embeddings'\n",
    "\n",
    "c1 = ContrieverCB()\n",
    "\n",
    "c1.generate_embeddings(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
